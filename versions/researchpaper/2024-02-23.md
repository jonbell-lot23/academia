# Augmented Text

## Abstract

**Introduction to Augmented Text**
Traditional reading was an analog experience, with no interactivity. On the other hand, the modern experience of multimedia is often very interactive but harder to read with the same flow as a book. Augmented Text aims to take the best from both worlds, the feeling of flow while reading a book, but with the assistance of software.

**Research Objective**
This work addresses one question: How can we enhance the reading experience through technology without compromising the essence of traditional reading? It utilities a methodology that combines qualitative and quantitative approaches in order to quantify the "essence" of traditional reading with enhancements that benefit readers of educational and informational content.
## Introduction

#### Reading is not natural, and comprehension is hard
The evolution of literacy, as explored in "Proust and the Squid" by Maryanne Wolf, underscores the intricate cognitive processes involved in reading and understanding text. Wolf's analysis reveals that reading is not an innate human ability but a complex skill that our brains have adapted to perform over thousands of years, fundamentally changing the way we think, communicate, and perceive the world​​​[](https://mindfultechnics.com/proust-and-the-squid-book-review/)​. Reading, as opposed to simply hearing words, activates a unique interplay of brain circuits, fostering deeper comprehension and critical thinking. This is in stark contrast to oral traditions, which Noam Chomsky and others have established are innate to the human experience, and require less effort to master.

Because comprehending the written word is such a specialised process, humankind has long relied on tools and intermediaries to not just read, but to more deeply comprehend and understand. Educational institutions and religious organisations are the most obvious examples at a societal level, but it can be argued that most of human experience isn't about the lived experience, but making sense of it. This means that comprehension, not just experience, is a focal point for society. From the ancient scribes of organised religions who transcribed sacred texts, making the profound teachings accessible to a broader audience, to the establishment of universities in the medieval period, which became centres for scholarly study and interpretation of complex works, these intermediaries have been instrumental in the dissemination of knowledge. They not only provided the tools for literacy but also fostered an environment where comprehension and critical thinking were cultivated.

#### Software can help with comprehension, but at what cost?
With the development of the printing press and then the internet, the volume of things to read and experience increased exponentially, but the ability to comprehend is still at a premium. Educational and media organisations who initially turned to multimedia such as audio and video then discovered more complex forms of educational software to assist with comprehending information, from explainer videos to interactive data visualisations to simulations and educational software. While this has happened, the rise of more shallow reading patterns in the digital age has brought up questions about the potential impact on deep thinking, understanding, and comprehension. We've never had more media to consume, and more ways to understand it, leading to a bounty of opportunity but also a feeling of overwhelm. We have more ways than ever to be helped, but are those helpful features distracting from the essence and comprehension of a reading experience?

Bret Victor's concepts of Explorable Explanations and Alan Kay's Active Essays stand out as pioneering examples of how text can be augmented to offer more interactive and immersive learning experiences. These innovations allow readers to engage with content in dynamic ways, enabling a deeper exploration of topics and concepts through interactive visuals, simulations, and embedded coding environments. However, this evolution towards increasingly feature-rich digital texts brings forth a critical question: at what point does the augmentation of books with software and interactive elements detract from the essence of traditional reading?

"The Web's Grain," a critique on digital text design, serves as a cautionary reference point, highlighting the potential pitfalls of over-augmentation. It suggests that there exists a delicate balance between enhancing the readability and educational value of text through digital means and preserving the core experience of reading that books have offered for centuries. The challenge lies in integrating technological advancements in a way that complements rather than overwhelms the fundamental nature of reading, ensuring that books retain their intrinsic value as a medium for thought, reflection, and learning in the digital age. (TODO: Snowfall reference)

#### The central question we're looking to address

> How much can we enhance the reading experience through technology without compromising the essence of traditional reading?

This inquiry seeks to find a sweet spot between software and traditional books, where the augmentation of text with digital tools enriches the reader's engagement and understanding without eroding the fundamental experience of reading—a practice deeply rooted in human culture and cognitive processes.

To address this, the research will explore a spectrum of experiences that range from the simplicity of traditional books to the complexity of experimental interactive software. This exploration aims to identify strategies and methodologies that preserve the core of reading while leveraging the potential of modern technology to make texts more accessible, interactive, and engaging. By examining instances where multimedia integration has either stalled or failed to enhance the reading experience, such as in the stagnation of multimedia or the limited impact of games in this context, the study will highlight the limitations of current approaches.

Furthermore, the assertion that clinging solely to the traditional reading experience is inadequate in today's digital age underpins the necessity for a nuanced approach. This research advocates for a middle ground that respects the timeless value of literacy and the contemplative nature of reading, while embracing the possibilities that digital innovations offer for making texts more alive, interactive, and tailored to individual learning styles.

Through a methodological framework that includes both theoretical analysis and practical experimentation, this study aims to contribute to the ongoing dialogue about the evolution of reading in the digital era. It will seek to offer insights and recommendations for designers, educators, and content creators on how to craft reading experiences that are both enriched by technology and deeply respectful of the literary tradition that has shaped human thought and culture for millennia.

(TODO: accessibility)
## Methodology

#### Methodological Overview
This work employs a mixed-methods approach. First, it uses the Touch Level Model (TLM) for comparative analysis of different reading-based interactions, such as the scoring the relative time it takes to access a footnote in print versus digital formats. Next, Nielsen's Heuristic Evaluation is utilised to assess four key areas: Flow, Utility, Development Effort, and Customisation Effort. These four metrics provide a qualitative measure of the augmented text's design and usability, and will be defined in further detail below. Finally, we'll factor in Raskin's Efficiency Score, an analysis of Fitts' Law, and Hick's Law. By scoring interactions across multiple heuristics, we aim to provide a wide-ranging score that helps understand the pros and cons of each approach.
    
#### Criteria Definition
To develop a comprehensive evaluation model for augmented text, the methodology combines several components, each contributing unique insights:

1. **Touch Level Model (TLM):** Quantifies touch interactions, providing a baseline for comparing the efficiency of gestures and taps in augmented texts.
2. **Flow:** Measures how seamlessly users can navigate and engage with the text, emphasizing the importance of a distraction-free reading experience.
3. **Utility:** Evaluates the added value of augmented features in enhancing understanding and engagement, highlighting the relevance and effectiveness of these enhancements.
4. **Development Effort:** Assesses the resources required to implement augmented features, considering both time and technical complexity.
5. **Customization Effort:** Examines the ease with which users can personalise their reading experience, reflecting on user autonomy and adaptability.
6. **Raskin's Efficiency Measures:** Applies a broader view of information efficiency, focusing on how effectively augmented text conveys information with minimal user effort.
7. **Fitts’ Law:** Integrates principles of human motor system behavior to evaluate the physical ease of interacting with augmented text features.
8. **Hick’s Law:** Considers the cognitive load in decision-making, particularly how feature variety and complexity impact user choices and response times.

Combining these elements provides a holistic view, balancing objective performance metrics with subjective user experience assessments. This "cocktail" of data offers a nuanced understanding of augmented text's impact, guiding optimisations that enhance readability, engagement, and ease of use without compromising the essence of reading

#### Approach
This study will analyse a variety of reading tasks that individuals may encounter, utilising a custom "report card" to score different approaches to augmented text. By assessing how each approach fares against specific criteria such as flow, utility, development effort, and customisation effort, the study will provide a personalised evaluation of the effectiveness of various augmented reading experiences. This method allows for a nuanced comparison of how different technologies and design choices impact the reading process.

#### Limitations and Concepts Out of Scope

- The analysis will not include objective data for task completion times or effectiveness.
- There will be no surveys or interviews conducted with a diverse group of participants; instead, the study relies on one researcher's value judgments and estimates.
- The focus is on evaluating augmented text through theoretical and subjective lenses rather than empirical user data collection.
- Accessibility (TODO: explain this more)

#### Ethical Considerations

Not applicable to this study, as it does not involve human participants or data collection that raises ethical concerns.

## Findings

### Summary of findings

1. **Context is king**: Across the findings, we see that doing nothing to help someone understand context always tests worse than doing something. This is an unsurprising result, but leads to finding #2, with its inconvenient implications.

2. **Authoring context is extremely difficult:** In a perfect world, every word, paragraph, or full paper would always provide context that doesn't take you out of flow. But in the real world, every one of these features requires development, testing, upcoming, and training. The key here is not to build cool features, but to understand the tradeoffs inherent in creating and publishing content.

3. **We need better metrics to rate ROI:** If a feature takes a year to develop, but only saves someone twenty seconds of time, it has poor ROI. The problem is that despite my efforts here, there's no standardised way to quantify if a feature that adds helpful content could be worth it.

4. **Some things are simply not possible without augmented text:** Many of the items compared boil down to a clear comparison between task completion across two flows. But some can't be compared because it's simply not possible to do without a change in technology. This is part of the tradeoff discussion.

5. **The possibilities are vast and contextual:** I've carved off a small handful of examples to compare here, but any publication of content could come up with new features. For example, imagine tools that help understand memes, or completely different tools designed for lawyers or doctors to understand their complex fields.

### Raw results
For each of the items below, I've provided a standardised reading of how each process fared in my analysis.


<img src="media/spreadsheet1.jpg" />


### Baseline Reading, Full Comprehension

- **TLM steps:** R (read text for comprehension)
- **Total Time:** Variable; assume an average reading speed of 250 words per minute for complex academic text.
- **Sequence:** R

### Looking up a Word from a Paperback

*   **TLM steps:** M (form goal) + H (put down book) + M (decide to grab device) + T (grab device) + P (navigate) + K (type query) + T (set down device)
*   **Total Time:** 1.35 + 0.4 + 1.35 + 5 + 1.1 + 7 + 0.2 = 16.4 seconds
*   **Sequence:** MHTM\[PTK\]T

### Looking up a Word in iOS

*   **TLM steps:** M + P + T (long-press) + M (choose 'Define') + T (select 'Define') + T (dismiss)
*   **Total Time:** 1.35 + 1.1 + 0.5 + 1.35 + 0.2 + 0.2 = 4.7 seconds
*   **Sequence:** MPTMTT

### Looking up a Word on Android

*   **TLM steps:** M + P + T (long-press) + M (decide action) + T (search action) + P (navigate to search) + K (type in query) + R(t) (read results) + T (select result)
*   **Total Time:** 1.35 + 1.1 + 0.5 + 1.35 + 0.2 + 1.1 + 1.2 + 10 + 0.2 = 16.95 seconds
*   **Sequence:** MPTM\[TPTKMPTRT\]T

### Looking up a Nonsense Word in iOS

*   **TLM steps:** M + P + T (long-press) + M (decide action) + T (search action) + P (navigate to search) + K (type in query) + R(t) (read results) + T (select result)
*   **Total Time:** 1.35 + 1.1 + 0.5 + 1.35 + 0.2 + 1.1 + 1.2 + 10 + 0.2 = 16.95 seconds
*   **Sequence:** MPTM\[TPTKMPTRT\]T

### Looking up a Word on Kindle X-Ray

*   **TLM steps:** M + P + T (select X-Ray) + T (select word)
*   **Total Time:** 1.35 + 1.1 + 0.2 + 0.2 = 2.85 seconds
*   **Sequence:** MPTT

### Looking up a Nonsense Word on Kindle

*   **TLM steps:** M + P + T (select X-Ray) + T (select word)
*   **Total Time:** 1.35 + 1.1 + 0.2 + 0.2 = 2.85 seconds
*   **Sequence:** MPTT

### Following a Reference to Other Media

- **TLM steps:** M (decide to follow reference) + P (locate reference) + T (tap or click on reference) + R(t) (wait for media to load and start)
- **Total Time:** 1.35 (decide) + 1.1 (locate) + 0.2 (tap) + 5 (load and start) = 7.65 seconds
- **Sequence:** MPT[R]


### Following a Hyperlink to Other Media

- **TLM steps:** M (decide to explore hyperlink) + P (point to hyperlink) + T (click hyperlink) + R(t) (load new media content)
- **Total Time:** 1.35 (decide) + 1.1 (point) + 0.2 (click) + 5 (load content) = 7.65 seconds
- **Sequence:** MPT[R]


### Following a Footnote

*   **TLM steps:** M (decide to follow) + P (find footnote) + T (turn pages) + R(t) (read footnote)
*   **Total Time:** 1.35 (decide) + 1.1 (find) + 12.55 (turn and find)
*   **Sequence:** MPT\[R\]

### Popover Footnotes

*   **TLM steps:** M (decide to view) + P (point to footnote) + T (tap footnote)
*   **Total Time:** 1.35 (decide) + 1.1 (point) + 0.2 (tap) = 2.65 seconds
*   **Sequence:** MPT

### Comparing Two Images Across Two Pages (Traditional)

- **TLM steps:** M (decide to compare images) + P (locate first image) + R(t) (observe first image) + P (locate second image) + R(t) (observe second image)
- **Total Time:** 1.35 (decide) + 1.1 (locate first) + 5 (observe first) + 1.1 (locate second) + 5 (observe second) = 13.55 seconds
- **Sequence:** MPRPRP



### Before and After Slider

*   **TLM steps:** M (decide to interact) + P (point to slider) + T (tap and drag slider)
*   **Total Time:** 1.35 (decide) + 1.1 (point) + 0.2 (tap and drag) = 2.65 seconds
*   **Sequence:** MPT

### Remembering Where You Last Left Off

- **TLM steps:** M (decide to mark current location) + P (point to bookmark feature) + T (activate bookmark or note feature)
- **Total Time:** 1.35 (decide) + 1.1 (point) + 0.2 (activate) = 2.65 seconds
- **Sequence:** MPT



### Last Read Indicator

*   **TLM steps:** M (decide to stop reading) + T (close book/app)
*   **Total Time:** 1.35 (decide) + 0.2 (close) = 1.55 seconds
*   **Sequence:** MT

### Remembering an Old Tab

- **TLM steps:** M (decide to recall an old tab) + P (navigate to browser tab overview or history) + T (select the old tab)
- **Total Time:** 1.35 (decide) + 1.1 (navigate) + 0.2 (select) = 2.65 seconds
- **Sequence:** MPT


### Reference Labels

*   **TLM steps:** M (recognise the need to track) + P (point to label) + T (activate label)
*   **Total Time:** 1.35 (recognise) + 1.1 (point) + 0.2 (activate) = 2.65 seconds
*   **Sequence:** MPT

### Seeing How an Article Changed

*   **TLM steps:** M (decide to use Article Diff) + P (navigate to Article Diff option) + T (activate Article Diff) + R(t) (review changes)
*   **Total Time:** 1.35 (decide) + 1.1 (navigate) + 0.2 (activate) + 10 (review) = 12.65 seconds
*   **Sequence:** MPT\[R\]

### Article Diff

- **TLM steps:** M (decide to view document revisions) + P (point to Article Diff feature) + T (select Article Diff feature) + R(t) (review document revisions)
- **Total Time:** 1.35 (decide) + 1.1 (point) + 0.2 (select) + Variable (review changes)
- **Sequence:** MPT[R]

### Understanding Dynamic Numbers in an Article

*   **TLM steps:** M (decide to interact) + P (point to the interactive element) + T (tap or click the interactive number)
*   **Total Time:** 1.35 (decide) + 1.1 (point) + 0.2 (tap) = 2.65 seconds
*   **Sequence:** MPT

###   Interactive Numbers

- **TLM steps:** M (decide to input personal data) + P (navigate to input field) + T (tap to activate input field) + K (type in personal data, e.g., salary or start date) + R(t) (observe changes in the document to reflect personal context)
- - **Total Time:** 1.35 (decide) + 1.1 (navigate) + 0.2 (tap) + 5 (type) + 10 (observe changes) = **17.65 seconds**
- **Sequence:** MPTK[R]

### Backtracking Browser History Through a Complex Academic Text

- **TLM steps:** M (decide to backtrack) + P (point to back button or history) + T (tap or click to go back) + R(t) (review previous content)
- **Total Time:** 1.35 (decide) + 1.1 (point) + 0.2 (tap) + 5 (review) = 7.65 seconds + Review Time
- **Sequence:** MPT[R]

### Personal Breadcrumbs

- **TLM steps:** M (decide to review navigation history) + P (point to Personal Breadcrumbs feature) + T (activate Personal Breadcrumbs feature) + R(t) (observe navigation path)
- **Total Time** = 1.35 (decide) + 1.1 (point) + 0.2 (activate) + 5 (observe path) = **7.65 seconds**
- **Sequence:** MPT[R]

### Quickly Seeing Popular Nav Elements

- **TLM steps:** n/a
- **Total Time:** n/a
- **Sequence:** n/a

### Digital Patina

- **TLM steps:** M (recognise visited elements) + P (point to elements with digital patina) + R(t) (decide based on visited status)
- **Total Time** = 1.35 (recognise) + 1.1 (point) + 1.35 (decide) = **3.8 seconds**
- **Sequence:** MPR

### Summarising an Article or Concept

- **TLM steps:** R (read article) + M (decide to find summary) + P (pick up printed materials) + S (search for summary) + R(t) (read summary) + N (take notes, optional)
- **Total Time:** Variable (reading article) + 1.35 (decide) + 0.5 (pick up/navigate) + Variable (search) + Variable (read summary) + Variable (note-taking)
- **Sequence:** RMPS[R][N]

### Summarise Widget (Hard-coded)

- **TLM steps:** M (decide to use widget) + P (locate widget) + T (activate widget) + R(t) (read summary)
- **Total Time:** 1.35 (decide) + 1.1 (locate) + 0.2 (activate) + 15 (read summary) = 17.65 seconds + Reading Time
- **Sequence:** MPT[R]

### Summarise Widget (AI)

- **TLM steps:** Similar to the hard-coded widget but might include an additional step for selecting options or providing input to the AI for customization.
- **Total Time:** Similar to hard-coded, with potential addition for AI interaction: 1.35 (decide) + 1.1 (locate) + 0.2 (activate) + 2 (AI interaction) + 15 (read summary) = 19.65 seconds + Reading Time
- **Sequence:** MPTM[R]
 

## Discussion

### Context is king
This work has studied how much we can enhance the reading experience without compromising the essence of traditional reading. which implies that help is always better than no help in this context. It's a statement so obvious as to seem trite, but it will be the foundation we build our entire discussion and further works on, so it's worth stress testing it a bit before we proceed. We need to confirm: is more help always better?

To illustrate, let's imagine you find a book in a store off Cuba Street in Wellington, New Zealand. You flip open the first pages and spot this introductory passage:

> There are two questions which I would like to begin with. First, what kind of critical and inventive thinking is required to take the various movements in software forward into those areas which are necessary if software oIigopoIies are to be undermined? But further, how are we to develop the capacity for unleashing the unexpected upon software and the certainties which form it?

Imagine you understand the passage perfectly, and need no assistance understanding any of the vocabulary or concepts. If that were the case, you might be puzzled by a second paragraph directly after the first one, perhaps saying something like this:

>*(In case you didn't understand the prior passage, it's asking two things: First, what smart ideas do we need to make software better and challenge big companies? Second, how can we make software more surprising?)*

Or what if there was a follow-up paragraph in another language, such as:

>*(In case you wanted to read the above passage in Maori: E rua nga pātai e hiahia ana ahau ki te tīmata. Tuatahi, he aha te momo whakaaro takenui me te waihanga e hiahiatia ana hei tango i ngā momo nekeneke i roto i ngā pūmanawa whakamua ki aua wāhi e hiahiatia ana mēnā me whakararuraru ngā pūmanawa oIigopoIies? Engari anō, me pēhea tātau e whakawhanake ai i te kaha mō te tuku i te ohorere ki ngā pūmanawa me ngā mea e hanga ana?)*

If you didn't ask for a simplified English or a Maori version, the additional help wouldn't seem like help at all. It would instead feel like clutter or an annoyance getting in the way of your main goal, reading the text. This is a clear demonstration of why help, when not asked for, might not be helpful at all.

But what about someone in the opposite situation? What if they read the above passage and didn't know what the word "oIigopoIies" means? What then? That's where help is valuable. Maybe they ask their friend, who accurately defines what the word means, but the meaning of the text still escapes comprehension. What is a "software oIigopoIy?" Why should they be undermined? Perhaps they do a search on Google for "[software oligopolies](https://www.google.com/search?q=software+oIigopoIies)," where as of the writing of this text in February 2024, Google returns no valuable context, believing instead that I meant to search for "software logos" or "software tipos."

Maybe they buy the book to ask their professor about it the next day, who can accurately explain the word, the implication behind "software oIigopoIies," the main thrust of the argument, and why the author might be arguing for them to be undermined. But that's less likely than what most people do: we notice words or concepts that we don't understand, but we don't take special action to learn them. We might be curious, but traditional books don't provide the tools to quickly learn, so we abandon the task.

What if a person could touch on a word in any physical book and learn the definition right away? It wouldn't require asking the friend, or Google, or their professor. It would be faster, tailored to the text, and even tailored to the era. For example, the person could tap the word "software oIigopoIies" and the definition could say "these days, this might be written as 'big tech', like Apple, Meta, Google, and Microsoft." Or perhaps the reader is deeply interested in anticompetitive practices from Microsoft, so a smart and customised definition software could report something like "Microsoft could be described as a "software oIigopoIy" as a way to reach the reader more directly. This is not possible today with physical books, but ebooks and other reader software can.

In the findings, looking up a word on iOS resulted in a LTM sequence of MPTMTT, which is estimated to take 4.7 seconds. In contrast, looking up a word in a physical copy of a book isn't possible, returning an LTM sequence of MHTM[PTK]T, an estimated time of 16.4 seconds, (representing the fastest estimated time someone can quit one app and search for a definition in a dictionary app), and a failing task. This neatly demonstrates the difference between not being able to access answers or context without external help versus having context as part of the reading experience.

Now we'll try a curveball. iOS does a good job defining words when they're in the English language, but fails when it doesn't recognise a word. For example, imagine a reader is enjoying the novel Dune, and they long-press the capitalised word Adept, a term that has special meaning in the Dune literature. iOS will return the English language translation for the word, despite the capitalisation, rather than the actual definition someone is looking for when reading Dune. Worse still is what happens when you try to define a word that doesn't exist at all. If our reader attempts to look up the word Auqaf, they'll be told by iOS that the word isn't available and instead show the definition of the word "Aqua." These failures result in LTM sequences of MPTM[TPTKMPTRT]T, taking 16.95 seconds, conservatively. It could be argued that the additional confusion of expecting a result and getting the wrong one would add more cognitive load and time than simply not having the feature at all.

As a contrast, Amazon's Kindle has a feature called X-Ray that doesn't just perform a simple dictionary search on a word, it attempts to pull other context into the reading experience. Looking up the same Dune words on Kindle result in LTM sequences of MPTT and a time of 2.85 seconds, the fastest of an option by far. When reading, context is king. Any software that can provide useful context is better than software that can't, provided that it only is offered when requested. And amongst different software options that can provide differing levels of quality and speed, the right answers delivered faster will always be better than ones with bad data or that are delivered slowly.

### Creating and socialising new ideas is extremely difficult

In the findings chart, I established a column for "developer effort" with only two options, green arrow up meaning "no big deal" or a red arrow down that means "kind of a big deal." This metric is comically, insultingly vague. The fact that everything from chatGPT's codebase to creating a simple tooltip both fall into the same category shows that this metric is meant for comparative purposes, not any kind of objective measure of difficulty. Put another way, I'm not attempting to say how hard something else, just that it's harder than the traditional way of doing it.

As a tangible example, "comparing two images across two pages" is a common action when seeing two images presented side by side, and requires no special effort from the author or developer. Therefore, it gets a green arrow pointing up. On the other hand, creating a Before and After slider isn't particularly difficult because it's such a common component. But it does take some effort to wire up, so it gets a red arrow pointing down. So these measurements provide a good comparative analysis, whereas a full accounting of exactly how complex each task may be is beyond the scope of this research.

But this metric goes beyond simple coding difficulty. We also need to factor in the complexity of a fragmenting media ecosystem, and the fact that no single entity owns the right to publish ideas on the internet. To illustrate this, let's say you wanted to argue that the Article Diff feature should exist for all media organisations. If you don't work at one, you probably won't get very far. But even if you are the CTO of the New York Times, and you successfully ship the feature to the New York Times audience, you have no control over what the Washington Post does, or the New Zealand Herald. Others may adopt your idea, but it's not really up to you. This means that no matter how good any of the ideas are that I've presented, no matter how much faster or better they are in objective ways, their reach is out of the control of any one entity. And that's a problem for improving the overall experience of reading text.

In doing my literature review, I noticed a lot of research talking about ways to make concepts such as Explorable Explanations more mainstream. A common suggestion was to make new programming languages or paradigms to help more people create helpful content to help people learn more, more effectively. But even with the best new programming language in the world, with the best tutorials, the best outreach content, the most motivated team, and the money to pay for it, it's still much harder to write code than write copy. Some organisations such as Pudding.cool and The New York Times have been able to fund this kind of work, but it's still a minority of all content. It's the opinion of the author that this is appropriate. Most reading should be reading, and even when teaching aids and illustrations are introduced, it should be the bare minimum required to get the main point across, and always something the user requests, rather than something that's pushed on them.

I want to put a very clear line in the sand here: despite all the advantages of augmented text, and in helping people add context to the content they're reading, it's still a tremendous technical challenge that is not easy to address. It won't be addressed or fixed by better programming languages or better ideas. Success of these ideas will emerge slowly and organically, in the marketplace of ideas. If a large organisation such as Wordpress decides to embrace some examples of Augmented Text, then its competitors decide to react in order to stay competitive, the ideas will spread. Slowly, and over time, some ideas might become popular enough in the mainstream. But it will take that, and nothing less than that, not a better programming language. 

### We need better metrics to rate ROI
My research struggled to come up with a conceptual framework to help understand which features could benefit from improvements, and by how much. If we could quantify actions easily, like knowing that following any hyperlink took exactly 3 seconds, or researching a footnote always took 7 seconds, I'd have a more objective measure to rely on. Instead, my methodology needed to rely on relative measures. This works well when comparing traditional to traditional approaches, but doesn't work as well when determining the overall benefit of a new feature.

I'd propose a new heuristic for determining the potential success of a new approach: estimate the total number of developer hours a feature might take, and compare it to how many hours we think it will save the audience. For example, if the "Interactive Numbers" feature only requires 8 developer hours to create and implement on a site, whereas one million people would use the feature and each would save 2 minutes, that means the effort took 8 hours but saved 33,333 hours, for an ROI of 4167:1.

On the other hand, imagine if "Summarise Widget (Hard-coded)" takes a team of 12 3 months to implement, but the overall user base it's serving means that only 1000 people will see it and get 5 minutes of value each. That means the team would spend 5,760 hours building a feature that users would get 83 hours of use out of each week, for a ratio of .0145:1. At this rate, it would take 69.12 weeks for the feature to break even. On one hand, that's more than a year for the ROI to pay off. On the other hand, if that year positions your media organisation favourably, and you become known as a site that doesn't just deliver news but helps you comprehend it, maybe that's an investment worth making. But either way, it's important to quantify these ideas in a way that helps determine if they're worth it or not, in as objective a way as possible. Even the best feature in the world, which would help literally everyone who saw it, needs to justify its investment. If only 100 people will see it, but it takes a million dollars to build it, that at least needs to be built into the ROI in some tangible way.

### Some things are simply not possible without augmented text
In the digital age, the evolution of text from static to dynamic through augmentation has opened new horizons that were previously unimaginable. Traditional text, while a cornerstone of knowledge transfer and communication for centuries, inherently possesses limitations that restrict the depth of interaction and engagement. This is where the notion that "Some Things Are Simply Not Possible Without Augmented Text" comes into play, underscoring a pivotal shift in how we perceive and interact with written content.

Augmented text transcends these limitations by embedding interactivity, multimedia, and context-aware features directly within the text, enabling a multifaceted reading experience that traditional mediums cannot offer. This enhancement is not merely about adding novelty to reading; it's about fundamentally expanding the capabilities of text to inform, educate, and engage.

One of the most significant advantages of augmented text is its ability to bridge comprehension gaps in real-time. Consider complex scientific papers or historical documents laden with specialized terminology. Without augmentation, readers might find themselves disengaged, lost in jargon that feels inaccessible. Augmented text, however, can instantly provide definitions, explanations, or visual aids at the point of need, seamlessly integrated into the reading experience. This immediacy transforms the act of reading from a passive to an interactive journey, where understanding is not just facilitated but enriched.

The capacity for personalization is another realm where augmented text shines. Traditional texts offer a one-size-fits-all approach that can't adapt to the diverse needs and preferences of its audience. Augmented text, conversely, can tailor the reading experience to individual users, accommodating different learning styles, languages, and even accessibility needs. This personalization extends the reach of text, making information not just available but accessible to a broader audience, including those with disabilities who might find traditional text formats challenging.

Augmented text also serves as a platform for creativity and exploration, enabling authors and educators to embed interactive elements, simulations, and exploratory tools within the text. This capability transforms the reading experience into an interactive journey, where readers can simulate experiments, visualise data dynamically, or explore scenarios within the narrative. Such interactivity invites readers to engage deeply with the content, fostering a more profound understanding and retention of information.

Moreover, augmented text overcomes the physical and digital boundaries that confine traditional text. Geographic and temporal constraints, which once limited the dissemination and relevance of information, are rendered moot. Augmented text can incorporate real-time data, connect readers across the globe through collaborative annotations, or update content to reflect the latest developments, ensuring the information remains relevant and timely.

Despite its potential, the widespread adoption of augmented text faces significant challenges, particularly in implementation. Developing sophisticated augmented text systems requires considerable investment in technology, design, and content creation. Moreover, the technological infrastructure to support such features must be universally accessible, posing a challenge in ensuring equitable access to the benefits of augmented text.

Looking ahead, the possibilities of augmented text are vast and largely untapped. As technology advances, we can anticipate even more innovative forms of augmentation, from augmented reality overlays that bring text to life in our physical environment to AI-driven personal assistants that provide contextual insights and support. These advancements promise to further dissolve the barriers between readers and the knowledge they seek, ushering in a new era of text that is not just read but experienced.

### The possibilities are vast and contextual
The exploration of augmented text thus far has only scratched the surface of its potential. By examining a select few examples, we've begun to understand its impact. However, the true breadth of possibilities it holds is as boundless as the diversity of content that exists in our world. Augmented text is not merely a tool for enhancing traditional reading experiences; it's a gateway to uncharted territories of knowledge and interaction.

Consider the realm of memes, a ubiquitous form of digital communication that blends humor, culture, and commentary. Augmented text could offer tools to dissect and understand the layers of meaning within a meme, contextualizing its references and nuances for those not in the know. Such tools could transform fleeting moments of entertainment into rich, educational experiences, broadening our understanding of digital culture.

The potential applications extend far beyond popular culture, reaching into the specialized and complex worlds of various professions. For lawyers, augmented text could revolutionise the way legal documents are interacted with, offering real-time annotations, precedent references, and legal interpretations at the touch of a word. This could demystify legal language, making it more accessible to practitioners and the public alike.

In the medical field, doctors and students could benefit from augmented textbooks and journals that offer interactive diagrams, patient case studies, and the latest research findings embedded directly within the text. This could facilitate a deeper understanding of medical conditions and treatments, enhancing the learning process and ultimately improving patient care.

The possibilities are indeed vast and contextual, limited only by our imagination and the technological advancements that continue to unfold. As augmented text evolves, it promises to reshape not only how we consume information but also how we interact with the world around us. It encourages a future where knowledge is more accessible, education is more interactive, and our capacity for understanding and innovation is boundless.

This vision of the future, powered by augmented text, is not just an aspiration but a call to action for creators, developers, and thinkers. It challenges us to envision and build new ways of sharing and discovering knowledge, to transcend the limitations of traditional text, and to embrace the vast, untapped potential that lies within augmented text.

As we stand on the precipice of this new era, it's clear that the journey ahead is filled with exciting possibilities. The exploration of augmented text is a path to unlocking new dimensions of understanding and engagement, promising to enrich our lives in ways we're only beginning to imagine.



----------
##  Future Work

#### Identifying Areas for Further Research

(Stay tuned)

## Conclusion

#### Summary of Key Findings

(Stay tuned)

#### Recommendations for Stakeholders

(Stay tuned)

### Acknowledgment of Limitations and Challenges

(TBD)

### Closing Thoughts

## References

(TBD)